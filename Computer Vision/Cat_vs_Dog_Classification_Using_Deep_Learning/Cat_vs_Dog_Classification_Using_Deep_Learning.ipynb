{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e82691",
   "metadata": {},
   "source": [
    "Cat_vs_Dog_Classification_Using_Deep_Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9b77f-4b67-44d2-8521-e327d497793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85db2358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\anilk\\AppData\\Local\\Temp\\ipykernel_28212\\337460670.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ef0bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "#Num GPUs Available: 1\n",
    "tf.test.is_built_with_cuda()\n",
    "#True\n",
    "print(tf.version. VERSION)\n",
    "#2.1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047c55a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c62dd5-ce0c-4d6d-9846-9bd9226118f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b82c3d3-a63a-4580-b6bc-4d9c8b72e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac3ba74-d109-4669-b2c7-52fb10f3a12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ab93ba7-c99b-43ae-82e0-878870aa1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is my first convololution layer \n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding=\"valid\",activation=\"relu\",input_shape=(256,256,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "#second convololution\n",
    "model.add(Conv2D(64,kernel_size=(3,3),padding=\"valid\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid'))\n",
    "#third convololution\n",
    "model.add(Conv2D(128,kernel_size=(3,3),padding=\"valid\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=2,padding='valid')) \n",
    "#adding first hidden layer with 128 neurons and relu activation\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "#adding second hidden layer with 64 neurons and relu activation\n",
    "model.add(Dense(64,activation='relu'))\n",
    "#here we have a 1 output since it is a binary classification\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac38adb3-dbe4-4b57-8abc-6f7f711cb0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               14745728  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,847,297\n",
      "Trainable params: 14,847,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4693f98-1f78-4c41-a41c-c69862c70213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae51219-b92d-40f3-88b6-3c63d07552de",
   "metadata": {},
   "source": [
    "Now comes the biggest challenge , giving data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e066ff12-e40c-44eb-b986-74a131980703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 4519 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#internally it is using generator concept which is there in python , we know we use \n",
    "#generator concept when we need memory efficient way to load something not directly\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=r\"C:/Users/anilk/Desktop/test\",\n",
    "    batch_size=32,\n",
    "    image_size=(256,256), #resytriction in image\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\"\n",
    "    \n",
    ")\n",
    "validation_ds =keras.utils.image_dataset_from_directory(\n",
    "    directory=r'C:/Users/anilk/Desktop/train',\n",
    "    batch_size=32,\n",
    "    image_size=(256,256),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c738bc3",
   "metadata": {},
   "source": [
    "In our dataset there are many photos , and their sizes are also very different \n",
    "\n",
    "if i want to pr\n",
    "\n",
    "in ML we do standardization and normalisation \n",
    "\n",
    "but in Dl we do min max Scaling (pixcel scaling) , unit scaling\n",
    "\n",
    "pixcel size is [0-255] , image size is 256*256 , if i want to compress pixcell size we have to  divide it by 255, then value is cmpressed between [0-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90acd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(image,label):\n",
    "    tf.cast(image/255,tf.float32)\n",
    "    return image,label\n",
    "train_ds = train_ds.map(process)\n",
    "validation_ds = validation_ds.map(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9245333b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TFE_GetMemoryInfo(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: handle, arg1: str) -> Dict[str, int]\n\nInvoked with: <capsule object NULL at 0x0000014DFB774D20>, PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of available GPUs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(physical_devices))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m physical_devices:\n\u001b[1;32m----> 7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(device\u001b[38;5;241m.\u001b[39mname, \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_memory_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\anilk\\miniconda3\\envs\\py310env\\lib\\site-packages\\tensorflow\\python\\framework\\config.py:576\u001b[0m, in \u001b[0;36mget_memory_info\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.experimental.get_memory_info\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_memory_info\u001b[39m(device):\n\u001b[0;32m    535\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Get memory info for the chosen device, as a dict.\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m  This function returns a dict containing information about the device's memory\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;124;03m    ValueError: Memory statistics not tracked, like '\"CPU:0\"'.\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_memory_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anilk\\miniconda3\\envs\\py310env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1630\u001b[0m, in \u001b[0;36mContext.get_memory_info\u001b[1;34m(self, dev)\u001b[0m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_physical_devices()\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m-> 1630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_GetMemoryInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: TFE_GetMemoryInfo(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: handle, arg1: str) -> Dict[str, int]\n\nInvoked with: <capsule object NULL at 0x0000014DFB774D20>, PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Number of available GPUs:\", len(physical_devices))\n",
    "\n",
    "for device in physical_devices:\n",
    "    print(device.name, tf.config.experimental.get_memory_info(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c1c77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 119s 137ms/step - loss: 3.1658 - accuracy: 0.5889 - val_loss: 0.6615 - val_accuracy: 0.5990\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 106s 135ms/step - loss: 0.6708 - accuracy: 0.5927 - val_loss: 0.6454 - val_accuracy: 0.6156\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 107s 137ms/step - loss: 0.6205 - accuracy: 0.6549 - val_loss: 0.7176 - val_accuracy: 0.5966\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 0.6338 - accuracy: 0.6243 - val_loss: 0.5922 - val_accuracy: 0.6734\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 99s 127ms/step - loss: 0.5328 - accuracy: 0.7062 - val_loss: 0.6062 - val_accuracy: 0.7123\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 100s 128ms/step - loss: 0.4576 - accuracy: 0.7606 - val_loss: 0.7663 - val_accuracy: 0.6917\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 0.3724 - accuracy: 0.8134 - val_loss: 0.8545 - val_accuracy: 0.6931\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 105s 134ms/step - loss: 0.3132 - accuracy: 0.8511 - val_loss: 0.8073 - val_accuracy: 0.7249\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 102s 130ms/step - loss: 0.2759 - accuracy: 0.8755 - val_loss: 0.8732 - val_accuracy: 0.7269\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 100s 128ms/step - loss: 0.2569 - accuracy: 0.8884 - val_loss: 0.5738 - val_accuracy: 0.7780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14dfb776710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,epochs=10,validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35f95b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8e2885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a54a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812720b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca6cb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_array = np.loadtxt(\"C:/Users/anilk/Downloads/image_array.txt\").reshape(1,256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01034a9e",
   "metadata": {},
   "source": [
    "model.save(\"C:\\Users\\anilk\\Desktop\\model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "516a0df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/anilk/Desktop/model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:/Users/anilk/Desktop/model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"C:/Users/anilk/Desktop/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "772258d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"C:/Users/anilk/Desktop/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdc79a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save_weights('C:/Users/anilk/Desktop/my_weights')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bdceaeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "a= model.predict(loaded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3207c803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5974293]]\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1df06e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_array = np.loadtxt(\"C:/Users/anilk/Downloads/image_array2.txt\").reshape(1,256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c91347ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n"
     ]
    }
   ],
   "source": [
    "a1 = model.predict(loaded_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4195a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99989235]]\n"
     ]
    }
   ],
   "source": [
    "print(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c077cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "[[0.6362219]]\n"
     ]
    }
   ],
   "source": [
    "loaded_array = np.loadtxt(\"C:/Users/anilk/Downloads/image_array3.txt\").reshape(1,256, 256, 3)\n",
    "a2 = model.predict(loaded_array)\n",
    "print(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9c40f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "[[0.6443196]]\n"
     ]
    }
   ],
   "source": [
    "loaded_array = np.loadtxt(\"C:/Users/anilk/Downloads/image_array4.txt\").reshape(1,256, 256, 3)\n",
    "a3 = model.predict(loaded_array)\n",
    "print(a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e7e4e092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "[[0.97005916]]\n"
     ]
    }
   ],
   "source": [
    "loaded_array = np.loadtxt(\"C:/Users/anilk/Downloads/image_array5.txt\").reshape(1,256, 256, 3)\n",
    "a5 = model.predict(loaded_array)\n",
    "print(a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d6beec",
   "metadata": {},
   "source": [
    "In this project i have faced many issue such that , \n",
    "\n",
    "Issue 1 : i have dream of training neural networks on my local system GPU , so i have faces multiple issues in that , i have windows 11 machine , and is 2024 year and tensorflow with GPU support is not supported in tensorflowversion greater than 2.10 , and for python version greater than 3.10 , so i have to first handle taht issue , and also i have to switch from jupyter notebook to VS code to run my model on GPU , due to vS code i am facing issue with matplotlib , but i handled that issue as well \n",
    "\n",
    "Issue 2: i am unable to read any image array in my vscode, i tried different libraries for that like Cv2, tensorflow.preprocessing as well, but i explictly generated image array of that specific image that i want to test with using given code , "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd3d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Path to your image\n",
    "image_path = \"/content/dog.67.jpg\"\n",
    "\n",
    "# Read the image and resize it to 256x256 during loading\n",
    "img = load_img(image_path, target_size=(256, 256))\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "img_array = img_to_array(img)\n",
    "\n",
    "# Expand dimensions for a batch of one image\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Remove the batch dimension for saving\n",
    "img_array = np.squeeze(img_array, axis=0)\n",
    "\n",
    "# Save the array to a text file\n",
    "np.savetxt(\"image_array5.txt\", img_array.reshape(-1, img_array.shape[-1]), fmt='%d')\n",
    "\n",
    "# Alternatively, save the array to a binary file for more compact storage\n",
    "np.save(\"image_array.npy\", img_array)\"\"\"\n",
    "\n",
    "# or to check right image array is generated or not \n",
    "\n",
    "\"\"\" import numpy as np\n",
    "\n",
    "# Load the array from the text file\n",
    "loaded_array = np.loadtxt(\"/content/image_array5.txt\").reshape(256, 256, 3)\n",
    "\n",
    "# Display the image to verify it is loaded correctly\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(loaded_array.astype('uint8'))\n",
    "plt.axis('off')  # Hide axis\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1493425",
   "metadata": {},
   "source": [
    "Issue 3 : from where i download dataset , here in train folder  , dog and cat images are in same , so i have to write script to make different folders of dog and cat , and in test folder all iamges are not caategoried * their names is also not specified , so i have to also write script to make validation dataset\n",
    "\n",
    "kaggle link where i downlaod dataset: https://www.kaggle.com/c/dogs-vs-cats/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a283b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to move photos to make 2 folders in train folder named cat and dog \n",
    "\"\"\"import os\n",
    "import shutil\n",
    "\n",
    "# Source directory containing dog and cat images\n",
    "source_dir = \"C:/Users/anilk/Downloads/dogs-vs-cats/test1/test1\"  # Replace with your actual directory path\n",
    "\n",
    "# Destination directories for sorted images\n",
    "dog_dir = \"C:/Users/anilk/Desktop/train\\dog\"\n",
    "cat_dir = \"C:/Users/anilk/Desktop/train\\cat\"\n",
    "\n",
    "# Create the destination directories if they don't exist\n",
    "if not os.path.exists(dog_dir):\n",
    "    os.makedirs(dog_dir)\n",
    "\n",
    "if not os.path.exists(cat_dir):\n",
    "    os.makedirs(cat_dir)\n",
    "\n",
    "# Move or copy images based on their filename pattern\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.startswith(\"cat\"):  # Move cat images to cat_dir\n",
    "        shutil.move(os.path.join(source_dir, filename), os.path.join(cat_dir, filename))\n",
    "    elif filename.startswith(\"dog\"):  # Copy dog images to dog_dir\n",
    "        shutil.copy(os.path.join(source_dir, filename), os.path.join(dog_dir, filename))\"\"\"\n",
    "\n",
    "\n",
    "# script to make validation dataset from training dataset \n",
    "\n",
    "\"\"\"import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Source directories\n",
    "train_dog_dir =  \"c:/Users/anilk/Desktop/test/dog\" # Replace with actual paths \"C:\\Users\\anilk\\Desktop\\train\\cat\"\n",
    "train_cat_dir = \"c:/Users/anilk/Desktop/test/cat\"  # Replace with actual paths\n",
    "\n",
    "# Destination directories\n",
    "test_dog_dir =  \"c:/Users/anilk/Desktop/train/dog\" # Replace with actual paths \"C:\\Users\\anilk\\Desktop\\train\\cat\"\n",
    "test_cat_dir =  \"c:/Users/anilk/Desktop/train/cat\" # Replace with actual paths\n",
    "\n",
    "# Number of images to copy per category (dog and cat)\n",
    "num_images_per_category = 2500\n",
    "print(2)\n",
    "# Copy random images from train_dog_dir to test_dog_dir\n",
    "for _ in range(num_images_per_category):\n",
    "    # Get a random image filename from train_dog_dir\n",
    "    filename = random.choice(os.listdir(train_dog_dir))\n",
    "\n",
    "    # Create the destination path for the image in test_dog_dir\n",
    "    dest_path = os.path.join(test_dog_dir, filename)\n",
    "\n",
    "    # Copy the image from source to destination\n",
    "    shutil.copy(os.path.join(train_dog_dir, filename), dest_path)\n",
    "    print(9)\n",
    "# Copy random images from train_cat_dir to test_cat_dir\n",
    "for _ in range(num_images_per_category):\n",
    "    # Get a random image filename from train_cat_dir\n",
    "    filename = random.choice(os.listdir(train_cat_dir))\n",
    "\n",
    "    # Create the destination path for the image in test_cat_dir\n",
    "    dest_path = os.path.join(test_cat_dir, filename)\n",
    "\n",
    "    # Copy the image from source to destination\n",
    "    shutil.copy(os.path.join(train_cat_dir, filename), dest_path)\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166f4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
